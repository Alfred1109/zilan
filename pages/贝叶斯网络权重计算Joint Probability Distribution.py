def main():    
    import streamlit as st
    import pandas as pd
    import altair as alt
    from urllib.error import URLError
    import numpy as np
    import pandas as pd
    from fontTools.merge.util import avg_int
    from pandasrw import load ,dump
    from sklearn.decomposition import PCA  # å¯¼å…¥ sklearn.decomposition.PCA ç±»
    from sklearn.utils import Bunch
    from sklearn.datasets import load_iris
    from sklearn.model_selection import train_test_split
    from sklearn.naive_bayes import GaussianNB
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import accuracy_score
    from sklearn.datasets import load_iris
    from sklearn.metrics import f1_score
    from sklearn.decomposition import FactorAnalysis as FA
    from pgmpy.models import BayesianModel
    from pgmpy.estimators import MaximumLikelihoodEstimator, AICScore
    from pgmpy.estimators import HillClimbSearch
    from pgmpy.estimators import K2Score, BicScore,BDeuScore,BDsScore,AICScore
    from pgmpy.inference import VariableElimination
    from pgmpy.models import BayesianNetwork
    from pgmpy.factors.discrete import TabularCPD
    import networkx as nx
    import japanize_matplotlib
    import matplotlib.pyplot as pyplot
    import pandas.plotting as plt



    st.set_page_config(page_title="è´å¶æ–¯ç½‘ç»œæƒé‡è®¡ç®—", page_icon="ğŸ“Š")

    st.markdown("# è´å¶æ–¯ç½‘ç»œæƒé‡è®¡ç®—")
    st.sidebar.header("è´å¶æ–¯ç½‘ç»œæƒé‡è®¡ç®—")
    st.write(
        """This demo shows how to use `st.write` to visualize Pandas DataFrames.
    (Data courtesy of the [UN Data Explorer](http://data.un.org/Explorer.aspx).)"""
    )


    origin_data=pd.read_csv('./thirdteam_checkname.csv')
    origin_data=origin_data#[origin_data.äºŒæŠ—ç”¨è¯==1 ]
    origin_data.fillna(0,inplace=True)#å°†è¡¨ä¸­çš„ç©ºå€¼å…¨éƒ¨æ›¿æ¢ä¸º0
    origin_data.replace('NaN',0,regex=True,inplace=True)#å¦‚æœå­˜åœ¨æ–‡æœ¬NANä¹Ÿå°†å…¶æ›¿æ¢ä¸º0
    df_encoded = origin_data[['ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰','å‡ºè¡€äº‹ä»¶','æ€§åˆ«(å¥³=1)','å¹´é¾„','è„‘æ¢—æ­»','ç³–å°¿ç—…','é«˜è¡€å‹','é«˜è¡€è„‚','å† å¿ƒç—…','åŠ¨è„‰ç˜¤ä½ç½®','åŠ¨è„‰ç˜¤å¤§å°','è¯ç‰©ä¾ä»æ€§è¯„åˆ†','äºŒæŠ—ç”¨è¯'
    ]]#æ­¤å¤„é€‰å–17åˆ—å› ç´ ä½œä¸ºæ ·ä¾‹ã€‚

    st.dataframe(df_encoded.describe().apply(lambda s: s.apply(lambda x: format(x, 'g'))))#ä½¿ç”¨pandasçš„describleå‡½æ•°ï¼Œæè¿°æ•´ä¸ªæ•°æ®

    #åˆ›å»ºæŒ‡å®šæ•°æ®é›†æ ¼å¼ï¼Œç”¨äºåç»­çš„è®­ç»ƒ
    matrix = df_encoded.values  #å°†dataframeè½¬åŒ–æˆnumpyæ ¼å¼
    matrix = np.nan_to_num(matrix)#å–å‡ºnumpyä¸­nanå€¼
    X = matrix[:, 2:]   # å–é™¤ç¬¬ä¸€åˆ—ä¹‹å¤–çš„æ‰€æœ‰åˆ—
    y = matrix[:, 1]    # å–ç¬¬ä¸€åˆ—
    # åˆ›å»ºä¸€ä¸ªBunchå¯¹è±¡ç”¨äºæ ‡å‡†åŒ–æœºå™¨å­¦ä¹ æ•°æ®
    dataset1 = Bunch(data=X, target=y, feature_names=['æ€§åˆ«(å¥³=1)','å¹´é¾„','è„‘æ¢—æ­»','ç³–å°¿ç—…','é«˜è¡€å‹','é«˜è¡€è„‚','å† å¿ƒç—…','åŠ¨è„‰ç˜¤ä½ç½®','åŠ¨è„‰ç˜¤å¤§å°','è¯ç‰©ä¾ä»æ€§è¯„åˆ†','äºŒæŠ—ç”¨è¯'], target_names=['ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰'])
    dataset = Bunch(data=X, target=y, feature_names=['æ€§åˆ«(å¥³=1)','å¹´é¾„','è„‘æ¢—æ­»','ç³–å°¿ç—…','é«˜è¡€å‹','é«˜è¡€è„‚','å† å¿ƒç—…','åŠ¨è„‰ç˜¤ä½ç½®','åŠ¨è„‰ç˜¤å¤§å°','è¯ç‰©ä¾ä»æ€§è¯„åˆ†','äºŒæŠ—ç”¨è¯'], target_names=['å‡ºè¡€äº‹ä»¶'])
    print(type(dataset),dataset.feature_names,dataset.target_names)

    # åŠ è½½bunchæ•°æ®é›†
    X = dataset.data
    y = dataset.target

    st.text(X[1])
    st.text(y[1])
    # å°†æ•°æ®è½¬æ¢ä¸ºpandas DataFrame
    df = pd.DataFrame(X, columns=dataset.feature_names)
    df['ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰'] = y

    # ç¦»æ•£åŒ–ç‰¹å¾
    # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨pd.qcutæ¥ç¦»æ•£åŒ–ç‰¹å¾ï¼Œå°†æ¯ä¸ªç‰¹å¾åˆ†ä¸ºå‡ ä¸ªåŒºé—´
    df_discrete = pd.get_dummies(df[['ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰','æ€§åˆ«(å¥³=1)','å¹´é¾„','è„‘æ¢—æ­»','ç³–å°¿ç—…','é«˜è¡€å‹','é«˜è¡€è„‚','å† å¿ƒç—…','åŠ¨è„‰ç˜¤ä½ç½®','åŠ¨è„‰ç˜¤å¤§å°','è¯ç‰©ä¾ä»æ€§è¯„åˆ†','äºŒæŠ—ç”¨è¯'
    ]])

    #ç¦»æ•£æ¦‚ç‡è¡¨
    def df_p(model,col):
        cpd = model.get_cpds(col)
        df = pd.DataFrame({
            'parents': cpd.variable,
            'states': cpd.state_names[col],
            'values': cpd.get_values().ravel()
        })
        return df
    #ç½‘ç»œç»˜å›¾ï¼Œjupyteré€‚ç”¨
    def showBN(model,save=False):
        '''ä¼ å…¥BayesianModelå¯¹è±¡ï¼Œè°ƒç”¨graphvizç»˜åˆ¶ç»“æ„å›¾ï¼Œjupyterä¸­å¯ç›´æ¥æ˜¾ç¤º'''
        from graphviz import Digraph
        node_attr = dict(
        style='filled',
        shape='box',
        align='left',
        fontsize='12',
        ranksep='0.1',
        height='0.2',
        fontname='SimHei'
        )
        dot = Digraph(node_attr=node_attr, graph_attr=dict(size="12,12"))
        seen = set()
        edges=model.edges()
        for a,b in edges:
            dot.edge(a,b)
        if save:
            dot.view(cleanup=True)
        #è¾“å‡ºåˆ°è·¯å¾„
        #dot.render('showbn.png', view=True)
        return dot

    # åŠ è½½dataframeæ ¼å¼æ•°æ®é›†
    hill_data=df_discrete#pd.read_csv('./train.csv')
    from pgmpy.estimators import HillClimbSearch
    from pgmpy.estimators import  K2Score, BicScore
    print(hill_data.head(5))

    # # åˆ›å»ºä¸€ä¸ªç©ºçš„ DAG å®ä¾‹
    start_dag = BayesianNetwork()

    # å‘ start_dag ä¸­æ·»åŠ ä¸æ•°æ®é›†ç›¸åŒçš„å˜é‡
    start_dag.add_nodes_from(['ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰','é«˜è¡€å‹','äºŒæŠ—ç”¨è¯'])
    start_dag.add_edges_from([('é«˜è¡€å‹','ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰'), ('äºŒæŠ—ç”¨è¯','ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰')])
    start_cpds = TabularCPD('ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰', 2, [[1,1,1,1],[1,1,1,1],],
                            evidence=['é«˜è¡€å‹', 'äºŒæŠ—ç”¨è¯'], 
                            evidence_card=[2,2])
    start_dag.add_cpds(start_cpds)
    showBN(start_dag,True)
    # åˆå§‹åŒ–çˆ¬å±±æœç´¢
    hc = HillClimbSearch(hill_data,state_names=start_dag)
    # æ‰§è¡Œçˆ¬å±±æœç´¢ï¼Œç¡®å®šç½‘ç»œç»“æ„
    best_model = hc.estimate(scoring_method=BDeuScore(hill_data))
    st.text(sorted(best_model.nodes()))
    st.text(best_model.edges())
    # åˆ›å»ºè´å¶æ–¯ç½‘ç»œå¯¹è±¡
    bn = BayesianNetwork(best_model.edges())
    showBN(best_model,True)


    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰æ•ˆ
    try:
        bn.check_model()
        print("Model is valid.")
    except ValueError as e:
        print("Model check failed:", e)


    # ä¼°è®¡å‚æ•°
    bn.fit(hill_data)
    bn.get_cpds()
    # # åˆå§‹åŒ–ä¼°è®¡å™¨å¯¹è±¡
    estimator = MaximumLikelihoodEstimator(bn,hill_data)

    # è·å–æ¯ä¸ªèŠ‚ç‚¹çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ
    cpds = estimator.get_parameters()
    # æ‰“å°æ¯ä¸ªèŠ‚ç‚¹çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ
    for cpd in cpds:
        print(f"CPD for {cpd.variable}:")
        st.text(cpd)
