def main():
    import streamlit as st
    import pandas as pd
    import altair as alt
    from urllib.error import URLError
    import numpy as np
    import pandas as pd
    from fontTools.merge.util import avg_int
    from pandasrw import load ,dump
    from sklearn.decomposition import PCA  # å¯¼å…¥ sklearn.decomposition.PCA ç±»
    from sklearn.utils import Bunch
    from sklearn.datasets import load_iris
    from sklearn.model_selection import train_test_split
    from sklearn.naive_bayes import GaussianNB
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import accuracy_score
    from sklearn.datasets import load_iris
    from sklearn.metrics import f1_score
    from sklearn.decomposition import FactorAnalysis as FA
    from pgmpy.models import BayesianModel
    from pgmpy.estimators import MaximumLikelihoodEstimator, AICScore
    from pgmpy.estimators import HillClimbSearch
    from pgmpy.estimators import K2Score, BicScore,BDeuScore,BDsScore,AICScore
    from pgmpy.inference import VariableElimination
    from pgmpy.models import BayesianNetwork
    from pgmpy.factors.discrete import TabularCPD
    import networkx as nx
    import japanize_matplotlib
    import matplotlib.pyplot as pyplot
    import pandas.plotting as plt


    st.set_page_config(page_title="DataFrame Demo", page_icon="ğŸ“Š")

    st.markdown("# DataFrame Demo")
    st.sidebar.header("DataFrame Demo")
    st.write(
        """è´å¶æ–¯ç½‘ç»œï¼ˆBayesian Networkï¼‰ï¼Œä¹Ÿç§°ä¸ºä¿¡å¿µç½‘ç»œï¼ˆBelief Networkï¼‰æˆ–æœ‰å‘æ— ç¯å›¾æ¨¡å‹ï¼ˆDirected Acyclic Graph, DAGï¼‰ï¼Œæ˜¯ä¸€ç§æ¦‚ç‡å›¾æ¨¡å‹ï¼Œç”¨äºè¡¨ç¤ºå˜é‡ä¹‹é—´çš„æ¡ä»¶ä¾èµ–å…³ç³»ã€‚å®ƒåŸºäºè´å¶æ–¯å®šç†ï¼Œå¯ä»¥ç”¨äºæ¨ç†å’Œå†³ç­–"""
    )



    origin_data=pd.read_csv('./thirdteam_checkname.csv')
    origin_data=origin_data#[origin_data.äºŒæŠ—ç”¨è¯==1 ]
    origin_data.fillna(0,inplace=True)#å°†è¡¨ä¸­çš„ç©ºå€¼å…¨éƒ¨æ›¿æ¢ä¸º0
    origin_data.replace('NaN',0,regex=True,inplace=True)#å¦‚æœå­˜åœ¨æ–‡æœ¬NANä¹Ÿå°†å…¶æ›¿æ¢ä¸º0
    df_encoded = origin_data[['ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰','å‡ºè¡€äº‹ä»¶','æ€§åˆ«(å¥³=1)','å¹´é¾„','è„‘æ¢—æ­»','ç³–å°¿ç—…','é«˜è¡€å‹','é«˜è¡€è„‚','å† å¿ƒç—…','åŠ¨è„‰ç˜¤ä½ç½®','åŠ¨è„‰ç˜¤å¤§å°','è¯ç‰©ä¾ä»æ€§è¯„åˆ†','äºŒæŠ—ç”¨è¯'
    ]]#æ­¤å¤„é€‰å–17åˆ—å› ç´ ä½œä¸ºæ ·ä¾‹ã€‚

    st.dataframe(df_encoded)

    st.dataframe(df_encoded.describe().apply(lambda s: s.apply(lambda x: format(x, 'g'))))#ä½¿ç”¨pandasçš„describleå‡½æ•°ï¼Œæè¿°æ•´ä¸ªæ•°æ®

    #åˆ›å»ºæŒ‡å®šæ•°æ®é›†æ ¼å¼ï¼Œç”¨äºåç»­çš„è®­ç»ƒ
    matrix = df_encoded.values  #å°†dataframeè½¬åŒ–æˆnumpyæ ¼å¼
    matrix = np.nan_to_num(matrix)#å–å‡ºnumpyä¸­nanå€¼
    X = matrix[:, 2:]   # å–é™¤ç¬¬ä¸€åˆ—ä¹‹å¤–çš„æ‰€æœ‰åˆ—
    y = matrix[:, 1]    # å–ç¬¬ä¸€åˆ—
    # åˆ›å»ºä¸€ä¸ªBunchå¯¹è±¡ç”¨äºæ ‡å‡†åŒ–æœºå™¨å­¦ä¹ æ•°æ®
    dataset1 = Bunch(data=X, target=y, feature_names=['æ€§åˆ«(å¥³=1)','å¹´é¾„','è„‘æ¢—æ­»','ç³–å°¿ç—…','é«˜è¡€å‹','é«˜è¡€è„‚','å† å¿ƒç—…','åŠ¨è„‰ç˜¤ä½ç½®','åŠ¨è„‰ç˜¤å¤§å°','è¯ç‰©ä¾ä»æ€§è¯„åˆ†','äºŒæŠ—ç”¨è¯'], target_names=['ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰'])
    dataset = Bunch(data=X, target=y, feature_names=['æ€§åˆ«(å¥³=1)','å¹´é¾„','è„‘æ¢—æ­»','ç³–å°¿ç—…','é«˜è¡€å‹','é«˜è¡€è„‚','å† å¿ƒç—…','åŠ¨è„‰ç˜¤ä½ç½®','åŠ¨è„‰ç˜¤å¤§å°','è¯ç‰©ä¾ä»æ€§è¯„åˆ†','äºŒæŠ—ç”¨è¯'], target_names=['å‡ºè¡€äº‹ä»¶'])
    print(type(dataset),dataset.feature_names,dataset.target_names)

    # åŠ è½½bunchæ•°æ®é›†
    X = dataset.data
    y = dataset.target

    # å°†æ•°æ®è½¬æ¢ä¸ºpandas DataFrame
    df = pd.DataFrame(X, columns=dataset.feature_names)
    df['ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰'] = y

    # ç¦»æ•£åŒ–ç‰¹å¾
    # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨pd.qcutæ¥ç¦»æ•£åŒ–ç‰¹å¾ï¼Œå°†æ¯ä¸ªç‰¹å¾åˆ†ä¸ºå‡ ä¸ªåŒºé—´
    df_discrete = pd.get_dummies(df[['ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰','æ€§åˆ«(å¥³=1)','å¹´é¾„','è„‘æ¢—æ­»','ç³–å°¿ç—…','é«˜è¡€å‹','é«˜è¡€è„‚','å† å¿ƒç—…','åŠ¨è„‰ç˜¤ä½ç½®','åŠ¨è„‰ç˜¤å¤§å°','è¯ç‰©ä¾ä»æ€§è¯„åˆ†','äºŒæŠ—ç”¨è¯'
    ]])

    #ç¦»æ•£æ¦‚ç‡è¡¨
    def df_p(model,col):
        cpd = model.get_cpds(col)
        df = pd.DataFrame({
            'parents': cpd.variable,
            'states': cpd.state_names[col],
            'values': cpd.get_values().ravel()
        })
        return df
    #ç½‘ç»œç»˜å›¾ï¼Œjupyteré€‚ç”¨
    def showBN(model,save=False):
        '''ä¼ å…¥BayesianModelå¯¹è±¡ï¼Œè°ƒç”¨graphvizç»˜åˆ¶ç»“æ„å›¾ï¼Œjupyterä¸­å¯ç›´æ¥æ˜¾ç¤º'''
        from graphviz import Digraph
        node_attr = dict(
        style='filled',
        shape='box',
        align='left',
        fontsize='12',
        ranksep='0.1',
        height='0.2',
        fontname='SimHei'
        )
        dot = Digraph(node_attr=node_attr, graph_attr=dict(size="12,12"))
        seen = set()
        edges=model.edges()
        for a,b in edges:
            dot.edge(a,b)
        if save:
            dot.view(cleanup=True)
        #è¾“å‡ºåˆ°è·¯å¾„
        #dot.render('showbn.png', view=True)
        return dot






    #é€šè¿‡äººå·¥è°ƒä¼˜çš„æ–¹å¼ï¼ŒæŠŠå­¦ä¹ å‡ºæ¥çš„æ¨¡å‹ç»“æ„è¿›è¡Œä¼˜åŒ–ï¼Œé€‰å–æœ€ç¬¦åˆçœŸå®ä¸–ç•Œçš„ç½‘ç»œç»“æ„ï¼Œè¿›è¡Œç»˜åˆ¶ã€‚
    figure_dag = BayesianNetwork()
    # å‘ start_dag ä¸­æ·»åŠ ä¸æ•°æ®é›†ç›¸åŒçš„å˜é‡
    figure_dag.add_nodes_from(['ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰','é«˜è¡€å‹','é«˜è¡€è„‚','å† å¿ƒç—…','åŠ¨è„‰ç˜¤ä½ç½®','åŠ¨è„‰ç˜¤å¤§å°','è¯ç‰©ä¾ä»æ€§è¯„åˆ†','äºŒæŠ—ç”¨è¯'])
    figure_dag.add_edges_from([('é«˜è¡€è„‚','ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰'), ('äºŒæŠ—ç”¨è¯','ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰'),('åŠ¨è„‰ç˜¤ä½ç½®','é«˜è¡€å‹'),('åŠ¨è„‰ç˜¤å¤§å°','é«˜è¡€å‹'),('é«˜è¡€å‹','äºŒæŠ—ç”¨è¯'),('é«˜è¡€è„‚','äºŒæŠ—ç”¨è¯'),('å† å¿ƒç—…','é«˜è¡€è„‚'),('è¯ç‰©ä¾ä»æ€§è¯„åˆ†','é«˜è¡€è„‚')])
    figure1_cpds = TabularCPD('ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰', 2, [[0.5,0.5,0.5,0.5],[0.5,0.5,0.5,0.5],],
                            evidence=['é«˜è¡€è„‚', 'äºŒæŠ—ç”¨è¯'], 
                            evidence_card=[2,2])
    figure2_cpds = TabularCPD('é«˜è¡€è„‚', 2, [[0.5,0.5,0.5,0.5],[0.5,0.5,0.5,0.5],],
                            evidence=['å† å¿ƒç—…', 'è¯ç‰©ä¾ä»æ€§è¯„åˆ†'], 
                            evidence_card=[2,2])
    figure3_cpds = TabularCPD('äºŒæŠ—ç”¨è¯', 2, [[0.5,0.5,0.5,0.5],[0.5,0.5,0.5,0.5],],
                            evidence=['é«˜è¡€å‹', 'é«˜è¡€è„‚'], 
                            evidence_card=[2,2])
    figure4_cpds = TabularCPD('é«˜è¡€å‹', 2, [[0.5,0.5,0.5,0.5],[0.5,0.5,0.5,0.5],],
                            evidence=['åŠ¨è„‰ç˜¤ä½ç½®', 'åŠ¨è„‰ç˜¤å¤§å°'], 
                            evidence_card=[2,2])
    figure5_cpds = TabularCPD('å† å¿ƒç—…', 2, [[0.5],[0.5],],)
    figure6_cpds = TabularCPD('è¯ç‰©ä¾ä»æ€§è¯„åˆ†', 2, [[0.5],[0.5],],)
    figure7_cpds = TabularCPD('åŠ¨è„‰ç˜¤ä½ç½®', 2, [[0.5],[0.5],],)
    figure8_cpds = TabularCPD('åŠ¨è„‰ç˜¤å¤§å°', 2, [[0.5],[0.5],],)
    figure_dag.add_cpds(figure1_cpds,figure2_cpds,figure3_cpds,figure4_cpds,figure5_cpds,figure6_cpds,figure7_cpds,figure8_cpds)
    showBN(figure_dag,True)
    fbn=figure_dag
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰æ•ˆ
    try:
        fbn.check_model()
        print("Model is valid.")
    except ValueError as e:
        print("Model check failed:", e)


    cpds=fbn.get_cpds()
    for cpd in cpds:
        print(f"CPD for {cpd.variable}:")
        print(cpd)

    #å°†æ¯ä¸ªèŠ‚ç‚¹çš„æ¦‚ç‡å–å‡å€¼ï¼Œæ ¹æ®äººå·¥è°ƒæ•´åçš„ç½‘ç»œå›¾è¿›è¡Œæ‰“å°ï¼Œç”±äºnxç›´æ¥ç”¨spring_layout(bn.to_direct())ç»˜åˆ¶ä¼šæŠ¥é”™ï¼Œå› æ­¤é€šè¿‡è·å–ç½‘ç»œç»“æ„å’Œè¾¹æƒé‡ï¼Œç”¨äººå·¥æ‹¼æ¥çš„æ–¹å¼ç»˜åˆ¶ï¼‰
    pyplot.rcParams["font.sans-serif"] = ["SimHei"]
    G = nx.MultiDiGraph(fbn.to_directed())
    # è·å–è´å¶æ–¯ç½‘ç»œçš„æ¡ä»¶æ¦‚ç‡ä½œä¸ºè¾¹çš„æƒé‡
    edge_weights = {}
    for edge in G.edges():
        parent = edge[1]
        child = edge[0]
        cpd = fbn.get_cpds(parent)
        if parent in cpd.variable:
            # ä½¿ç”¨ CPD ä¸­æ‰€æœ‰æ¦‚ç‡å€¼çš„å¹³å‡å€¼ä½œä¸ºæƒé‡
            weights = cpd.values
            weight = np.mean(weights)
            edge_weights[(child, parent)] = weight
            print(child,parent,weight)
    # è·å–è¾¹çš„æƒé‡
    edge_labels = nx.get_edge_attributes(G, 'weight')
    for (u, v) in G.edges():
        edge_labels[(u, v)] = edge_weights.get((u, v), 1)  # ä½¿ç”¨ä»CPDè·å–çš„æƒé‡æˆ–é»˜è®¤å€¼

    DG = nx.MultiDiGraph()
    for edge in G.edges():
        DG.add_edge(edge[0],edge[1],weight=edge_labels.get((edge[0],edge[1]),1))

    #ä½¿ç”¨ spring_layout ç®—æ³•ç”ŸæˆèŠ‚ç‚¹ä½ç½®
    pos = nx.spring_layout(DG, weight='weight', iterations=42)

    # ç»˜åˆ¶å›¾å½¢
    nx.draw(DG, pos, with_labels=True, node_color='lightblue', node_size=2000)

    # æ˜¾ç¤ºè¾¹çš„æƒé‡
    dg_labels = nx.get_edge_attributes(DG, 'weight')
    nx.draw_networkx_edge_labels(DG, pos, edge_labels=dg_labels)
    # æ ¹æ®æƒé‡è°ƒæ•´è¾¹çš„å®½åº¦
    edge_width = [edge_labels[(u, v)] * 1 for (u, v) in G.edges()]
    nx.draw_networkx_edges(G, pos, width=edge_width, edgelist=G.edges(), edge_color='gray')

    # æ˜¾ç¤ºå›¾å½¢
    pyplot.show()


    from pgmpy.readwrite import XMLBIFWriter
    from pgmpy.utils import get_example_model
    writer = XMLBIFWriter(fbn)
    writer.write_xmlbif('cpds.xml')
    # ä¸‹é¢çš„ä»£ç ä½¿ç”¨äº†VariableEliminationæ–¹æ³•ï¼Œäº¦å¯ç”¨BeliefPropagationï¼Œå…¶æœ‰ç›¸åŒçš„æ¥å£ã€‚
    # ä¸fitå‡½æ•°ç±»ä¼¼ï¼Œä¹Ÿæä¾›äº†è¾“å…¥dataframeçš„ç®€ä¾¿æ¨ç†æ–¹æ³•predictï¼Œå¦‚ä¸‹
    # åªè¦å‰”é™¤æƒ³é¢„æµ‹çš„åˆ—è¾“å…¥predictå‡½æ•°ï¼Œå°±å¯ä»¥å¾—åˆ°é¢„æµ‹ç»“æœçš„dataframe


    #ä»¥ä¸‹æ¨ç†ä¸»è¦è§£å†³çš„æ˜¯ï¼Œå½“å·²çŸ¥å…¶ä¸­ä¸€ä¸ªå˜é‡çš„æƒ…å†µä¸‹ï¼Œå¦å¤–å˜é‡çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
    model_infer = VariableElimination(fbn)
    q = model_infer.query(variables=['ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰'], evidence={'åŠ¨è„‰ç˜¤å¤§å°': 1, 'åŠ¨è„‰ç˜¤ä½ç½®': 1})
    print(q)
    #ä»¥ä¸‹æ¨ç†ä¸»è¦è§£å†³çš„æ˜¯ï¼Œå½“å·²çŸ¥å…¶ä¸­å˜é‡çš„æƒ…å†µä¸‹ï¼Œå¦å¤–å‡ ä¸ªå˜é‡çš„å¯èƒ½æ€§
    q = model_infer.map_query(variables=['åŠ¨è„‰ç˜¤ä½ç½®','åŠ¨è„‰ç˜¤å¤§å°'], evidence={'ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰': 1,'é«˜è¡€è„‚':0})
    print(q)

    #å¢åŠ forå¾ªç¯ï¼Œè·å–ä¸åŒå€¼ä¸‹çš„å˜é‡æ¦‚ç‡
    vari_name='äºŒæŠ—ç”¨è¯'
    fbnstats=fbn.states
    erkang_value=fbnstats[vari_name] #ç”±äºè¿™é‡Œåœ¨æ¨ç†æ—¶ï¼Œåªèƒ½å–è®­ç»ƒå¥½çš„è´å¶æ–¯ç½‘ç»œä¸­çš„é”®å€¼ï¼Œæ‰€ä»¥éœ€è¦ä»ç½‘ç»œä¸­è·å–èŠ‚ç‚¹æ‰€æœ‰å¯èƒ½å€¼ç”¨äºæ¨ç†ï¼Œè€Œä¸æ˜¯ç›´æ¥ä»åŸå§‹æ•°æ®ä¸­æŠ“å–å…¨é›†
    result=pd.DataFrame(columns=['å˜é‡','å˜é‡å€¼','ç›®æ ‡','ç›®æ ‡å€¼','æ¦‚ç‡'])
    i=0
    for j in (0,1):
        for value in erkang_value:
            model_infer = VariableElimination(fbn)
            q = model_infer.query(variables=['ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰'], evidence={ 'åŠ¨è„‰ç˜¤å¤§å°': 1, 'åŠ¨è„‰ç˜¤ä½ç½®': 1,vari_name:value})
            nake=q.variables[0]
            templist=[[vari_name,value,nake,q.state_names.get(nake)[j],q.values[j]]]
            if templist is None:
                continue
            tempdf=pd.DataFrame(templist,columns=['å˜é‡','å˜é‡å€¼','ç›®æ ‡','ç›®æ ‡å€¼','æ¦‚ç‡'])
            result =pd.concat([result,tempdf], verify_integrity=False) 
            i=i+1
    st.text(result)

    #é¢„æµ‹éœ€è¦éµå¾ªæµ‹è¯•é›†ä¸è®­ç»ƒé›†å­—æ®µä¸€è‡´åŸåˆ™ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚
    union_data=df_discrete[['ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰','é«˜è¡€å‹','é«˜è¡€è„‚','å† å¿ƒç—…','åŠ¨è„‰ç˜¤ä½ç½®','åŠ¨è„‰ç˜¤å¤§å°','è¯ç‰©ä¾ä»æ€§è¯„åˆ†','äºŒæŠ—ç”¨è¯']]
    train_data=union_data.iloc[1:2000]
    test_data=union_data.iloc[1501:3500]
    print(test_data)
    fbn.fit(train_data)
    print(fbn.check_model())
    test_data=test_data.drop('ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰', axis=1).reset_index(drop=True)
    print(len(test_data))
    y_pred = fbn.predict(test_data) #è¿™é‡Œæœ‰å¯èƒ½æŠ¥ç´¢å¼•é”™è¯¯ï¼ŒåŸå› æ˜¯åŸå§‹æ•°æ®çš„è¯ç‰©ä¾ä»æ€§è¯„åˆ†ä¸ºå°æ•°ï¼Œæ”¹ä¸ºæ•´æ•°åå¯ä»¥æ­£å¸¸è¿è¡Œã€‚
    print((y_pred['ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰'].values==train_data['ç¼ºè¡€äº‹ä»¶ï¼ˆæ’é™¤æ­»äº¡ï¼‰'].values).sum()/len(test_data))
    #æµ‹è¯•é›†ç²¾åº¦0.9363550593600126



